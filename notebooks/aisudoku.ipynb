{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d3cc44-e320-4abf-a99a-1964198ab3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.48.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.48.1\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "/home/nithin/miniconda3/envs/aisudoku/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudoku Grid:\n",
      "[0, 0, 1, 8, 9, 2, 6, 0, 0]\n",
      "[0, 9, 0, 0, 0, 0, 0, 2, 2]\n",
      "[0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 8, 4, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 3, 5, 4, 7, 9, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 5, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 3, 0]\n",
      "[0, 7, 0, 0, 0, 0, 0, 8, 0]\n",
      "[0, 2, 8, 1, 5, 3, 4, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the local directory where the model is saved\n",
    "save_directory = \"./trocr_model\"\n",
    "\n",
    "# Load the model, feature extractor, and tokenizer from the local directory\n",
    "model = VisionEncoderDecoderModel.from_pretrained(save_directory)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(save_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "# Create the pipeline using the locally loaded model, feature extractor, and tokenizer\n",
    "pipe = pipeline(\n",
    "    \"image-to-text\",\n",
    "    model=model,\n",
    "    feature_extractor=feature_extractor,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('sudoku.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Gaussian blur\n",
    "proc = cv2.GaussianBlur(img.copy(), (9, 9), 0)\n",
    "\n",
    "# Apply adaptive thresholding\n",
    "proc = cv2.adaptiveThreshold(proc, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Invert the image to make grid lines white\n",
    "proc = cv2.bitwise_not(proc, proc)\n",
    "\n",
    "# Dilate the image to enhance grid lines\n",
    "kernel = np.array([[0., 1., 0.], [1., 1., 1.], [0., 1., 0.]], np.uint8)\n",
    "proc = cv2.dilate(proc, kernel)\n",
    "\n",
    "# Find contours in the image\n",
    "contours, _ = cv2.findContours(proc, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort contours by area and select the largest one\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "polygon = contours[0]\n",
    "\n",
    "# Function to calculate the distance between two points\n",
    "def distance_between(p1, p2):\n",
    "    return np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "\n",
    "# Find the four extreme points of the contour\n",
    "bottom_right, _ = max(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "top_left, _ = min(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "bottom_left, _ = min(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "top_right, _ = max(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "\n",
    "# Extract the four corners\n",
    "crop_rect = [polygon[top_left][0], polygon[top_right][0], polygon[bottom_right][0], polygon[bottom_left][0]]\n",
    "\n",
    "# Calculate the side length of the square\n",
    "side = max([\n",
    "    distance_between(crop_rect[0], crop_rect[1]),\n",
    "    distance_between(crop_rect[1], crop_rect[2]),\n",
    "    distance_between(crop_rect[2], crop_rect[3]),\n",
    "    distance_between(crop_rect[3], crop_rect[0])\n",
    "])\n",
    "\n",
    "# Define the destination points for the perspective transform\n",
    "dst = np.array([[0, 0], [side - 1, 0], [side - 1, side - 1], [0, side - 1]], dtype='float32')\n",
    "\n",
    "# Perform the perspective transform\n",
    "m = cv2.getPerspectiveTransform(np.array(crop_rect, dtype='float32'), dst)\n",
    "warped = cv2.warpPerspective(img, m, (int(side), int(side)))\n",
    "\n",
    "# Infer the 81 cell grid\n",
    "squares = []\n",
    "side = warped.shape[0] // 9\n",
    "for j in range(9):\n",
    "    row = []\n",
    "    for i in range(9):\n",
    "        p1 = (i * side, j * side)  # Top-left corner of the cell\n",
    "        p2 = ((i + 1) * side, (j + 1) * side)  # Bottom-right corner of the cell\n",
    "        row.append((p1, p2))\n",
    "    squares.append(row)\n",
    "\n",
    "# Create a 9x9 grid to store the Sudoku puzzle\n",
    "sudoku_grid = [[0 for _ in range(9)] for _ in range(9)]\n",
    "\n",
    "# Extract and display cropped cells\n",
    "for row_idx, row in enumerate(squares):\n",
    "    for col_idx, square in enumerate(row):\n",
    "        p1, p2 = square\n",
    "        # Extract the cell\n",
    "        cell = warped[int(p1[1]):int(p2[1]), int(p1[0]):int(p2[0])]\n",
    "        \n",
    "        # Crop borders (adjust the margin as needed)\n",
    "        margin = int(cell.shape[0] * 0.15)  # 15% margin\n",
    "        cell = cell[margin:-margin, margin:-margin]\n",
    "        \n",
    "        # Save the cell image temporarily to pass it to the pipeline\n",
    "        cell_path = f\"cell_{row_idx}_{col_idx}.png\"\n",
    "        cv2.imwrite(cell_path, cell)\n",
    "        \n",
    "        # Use the pipeline to recognize text from the cell image\n",
    "        result = pipe(cell_path)\n",
    "        recognized_text = result[0]['generated_text']\n",
    "        \n",
    "        # Check if the recognized text is a single-digit number\n",
    "        if re.match(r'^\\d$', recognized_text):\n",
    "            sudoku_grid[row_idx][col_idx] = int(recognized_text)\n",
    "        else:\n",
    "            sudoku_grid[row_idx][col_idx] = 0  # Fill with 0 for invalid entries\n",
    "\n",
    "# Print the Sudoku grid\n",
    "print(\"Sudoku Grid:\")\n",
    "for row in sudoku_grid:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2354e5e-e4f7-4970-9238-704df98f6f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.48.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.48.1\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudoku Grid:\n",
      "[0, 0, 1, 8, 9, 2, 6, 0, 0]\n",
      "[0, 9, 0, 0, 0, 0, 0, 2, 0]\n",
      "[0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 8, 4, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 3, 5, 4, 7, 9, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 5, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 3, 0]\n",
      "[0, 7, 0, 0, 0, 0, 0, 8, 0]\n",
      "[0, 0, 8, 1, 5, 3, 4, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Path to the local directory where the model is saved\n",
    "save_directory = \"./trocr_model\"\n",
    "\n",
    "# Load the model, feature extractor, and tokenizer from the local directory\n",
    "model = VisionEncoderDecoderModel.from_pretrained(save_directory)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(save_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "# Create the pipeline using the locally loaded model, feature extractor, and tokenizer\n",
    "pipe = pipeline(\n",
    "    \"image-to-text\",\n",
    "    model=model,\n",
    "    feature_extractor=feature_extractor,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('sudoku.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Gaussian blur\n",
    "proc = cv2.GaussianBlur(img.copy(), (9, 9), 0)\n",
    "\n",
    "# Apply adaptive thresholding\n",
    "proc = cv2.adaptiveThreshold(proc, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Invert the image to make grid lines white\n",
    "proc = cv2.bitwise_not(proc, proc)\n",
    "\n",
    "# Dilate the image to enhance grid lines\n",
    "kernel = np.array([[0., 1., 0.], [1., 1., 1.], [0., 1., 0.]], np.uint8)\n",
    "proc = cv2.dilate(proc, kernel)\n",
    "\n",
    "# Find contours in the image\n",
    "contours, _ = cv2.findContours(proc, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort contours by area and select the largest one\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "polygon = contours[0]\n",
    "\n",
    "# Function to calculate the distance between two points\n",
    "def distance_between(p1, p2):\n",
    "    return np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "\n",
    "# Find the four extreme points of the contour\n",
    "bottom_right, _ = max(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "top_left, _ = min(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "bottom_left, _ = min(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "top_right, _ = max(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=lambda x: x[1])\n",
    "\n",
    "# Extract the four corners\n",
    "crop_rect = [polygon[top_left][0], polygon[top_right][0], polygon[bottom_right][0], polygon[bottom_left][0]]\n",
    "\n",
    "# Calculate the side length of the square\n",
    "side = max([\n",
    "    distance_between(crop_rect[0], crop_rect[1]),\n",
    "    distance_between(crop_rect[1], crop_rect[2]),\n",
    "    distance_between(crop_rect[2], crop_rect[3]),\n",
    "    distance_between(crop_rect[3], crop_rect[0])\n",
    "])\n",
    "\n",
    "# Define the destination points for the perspective transform\n",
    "dst = np.array([[0, 0], [side - 1, 0], [side - 1, side - 1], [0, side - 1]], dtype='float32')\n",
    "\n",
    "# Perform the perspective transform\n",
    "m = cv2.getPerspectiveTransform(np.array(crop_rect, dtype='float32'), dst)\n",
    "warped = cv2.warpPerspective(img, m, (int(side), int(side)))\n",
    "\n",
    "# Infer the 81 cell grid\n",
    "squares = []\n",
    "side = warped.shape[0] // 9\n",
    "for j in range(9):\n",
    "    row = []\n",
    "    for i in range(9):\n",
    "        p1 = (i * side, j * side)  # Top-left corner of the cell\n",
    "        p2 = ((i + 1) * side, (j + 1) * side)  # Bottom-right corner of the cell\n",
    "        row.append((p1, p2))\n",
    "    squares.append(row)\n",
    "\n",
    "# Create a 9x9 grid to store the Sudoku puzzle\n",
    "sudoku_grid = [[0 for _ in range(9)] for _ in range(9)]\n",
    "\n",
    "# Threshold for detecting blank cells (adjust as needed)\n",
    "blank_threshold = 10  # Standard deviation threshold\n",
    "\n",
    "# Extract and display cropped cells\n",
    "for row_idx, row in enumerate(squares):\n",
    "    for col_idx, square in enumerate(row):\n",
    "        p1, p2 = square\n",
    "        # Extract the cell\n",
    "        cell = warped[int(p1[1]):int(p2[1]), int(p1[0]):int(p2[0])]\n",
    "        \n",
    "        # Crop borders (adjust the margin as needed)\n",
    "        margin = int(cell.shape[0] * 0.15)  # 15% margin\n",
    "        cell = cell[margin:-margin, margin:-margin]\n",
    "        \n",
    "        # Check if the cell is blank\n",
    "        if np.std(cell) < blank_threshold:\n",
    "            sudoku_grid[row_idx][col_idx] = 0  # Mark as blank\n",
    "            continue  # Skip TrOCR prediction for blank cells\n",
    "        \n",
    "        # Save the cell image temporarily to pass it to the pipeline\n",
    "        cell_path = f\"cell_{row_idx}_{col_idx}.png\"\n",
    "        cv2.imwrite(cell_path, cell)\n",
    "        \n",
    "        # Use the pipeline to recognize text from the cell image\n",
    "        result = pipe(cell_path)\n",
    "        recognized_text = result[0]['generated_text']\n",
    "        \n",
    "        # Check if the recognized text is a single-digit number\n",
    "        if re.match(r'^\\d$', recognized_text):\n",
    "            sudoku_grid[row_idx][col_idx] = int(recognized_text)\n",
    "        else:\n",
    "            sudoku_grid[row_idx][col_idx] = 0  # Fill with 0 for invalid entries\n",
    "\n",
    "# Print the Sudoku grid\n",
    "print(\"Sudoku Grid:\")\n",
    "for row in sudoku_grid:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9950d-82c1-47c1-881f-2fb8b6dfeed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
